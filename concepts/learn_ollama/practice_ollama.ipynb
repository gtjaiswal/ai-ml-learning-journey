{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Imagine you want to ask the model \"llama3\" to \"Explain quantum physics in one sentence.\"\n",
    "\n",
    "Can you write the full Python code block to accomplish this?\n",
    "\n",
    "Make sure to include:\n",
    "\n",
    "Importing the necessary library.\n",
    "\n",
    "The correct URL.\n",
    "\n",
    "The payload (data).\n",
    "\n",
    "The command to send the request and print the actual text of the answer."
   ],
   "id": "fe66dceb412a36a3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-20T10:49:41.886239Z",
     "start_time": "2025-12-20T10:49:28.743998Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "from matplotlib.font_manager import json_load\n",
    "from requests import request\n",
    "\n",
    "# tags_url = \"http://127.0.0.1:11434/api/tags\"\n",
    "generate_url=\"http://127.0.0.1:11434/api/generate\"\n",
    "generate_data={\n",
    "    \"model\":\"llama3.1:latest\",\n",
    "    \"prompt\":\"Explain quantum physics in one sentence.\",\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "# check_models = request(method=\"get\",url=tags_url)\n",
    "# check_models.content\n",
    "\n",
    "response = request(method=\"post\",url=generate_url,json=generate_data)\n",
    "response.json()[\"response\"]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quantum physics is a branch of physics that describes the behavior of matter and energy at the smallest scales, where particles can exist in multiple states simultaneously, be connected across vast distances, and exhibit random and probabilistic properties.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Can you write the full Python code to:\n",
    "\n",
    "Define the URL for the chat endpoint.\n",
    "\n",
    "Create the payload (remember to include the model, your new messages list, and set stream to False).\n",
    "\n",
    "Send the POST request.\n",
    "\n",
    "Challenge: Try to print only the pirate's actual spoken text from the response. (Hint: The structure of the chat response is slightly different from the generate response. It follows the same structure as the messages you sent!)"
   ],
   "id": "4594d63c795b4788"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:50:02.146305Z",
     "start_time": "2025-12-20T10:49:47.551249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_url=\"http://127.0.0.1:11434/api/chat\"\n",
    "chat_payload={\n",
    "    \"model\":\"llama3.1:latest\",\n",
    "    \"messages\":[{\"role\":\"system\",\"content\":\"you are a pirate\"},{\"role\":\"user\",\"content\":\"where is the treasure?\"}],\n",
    "    \"stream\": False\n",
    "}\n",
    "response = request(method=\"post\",json=chat_payload,url=chat_url)\n",
    "response.json()[\"message\"][\"content\"]"
   ],
   "id": "c4b6fb0be0e7a9ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yer lookin' fer the loot, eh? Alright then, matey! The treasure be hidden on a mysterious island, said to be cursed by the sea goddess herself. They call it... (leaning in close) ...Tortuga's Tooth!\\n\\nIt be a rocky outcroppin', shrouded in mist and legend. Few have attempted to find it, but none have returned to tell the tale. Me hearty crew and I have been searchin' fer months, followin' cryptic maps and riddles left by me great-granddad, Blackbeak Bill.\\n\\nWe've got a map, see? (pulls out a tattered parchment) It points to a cave system beneath the island, where we'll need to navigate treacherous tunnels and avoid deadly traps. But that be just the beginnin'! Once inside, we'll have to solve a puzzle, unlockin' the treasure chamber door... and then we'll find... (dramatic pause) ...the Golden Chalice of Tortuga's Tooth!\\n\\nSo hoist the sails, me hearties, and set course fer Tortuga's Tooth! We'll need all our wits and cunning to claim this treasure and make it back to the ship in one piece! Yarrr!\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:51:00.454109Z",
     "start_time": "2025-12-20T10:50:57.457981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_without_payload={\n",
    "    \"model\":\"llama3.1:latest\",\n",
    "    \"messages\":[{\"role\":\"user\",\"content\":\"how can i reach there?\"}],\n",
    "    \"stream\": False\n",
    "}\n",
    "response = request(method=\"post\",json=chat_without_payload,url=chat_url)\n",
    "response.json()[\"message\"][\"content\"]\n"
   ],
   "id": "9049ec3b5d319134",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have any context about where you're trying to go. Could you please provide more information or clarify your question so I can better assist you? What are you trying to reach (a location, a contact, an object)?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:51:22.291960Z",
     "start_time": "2025-12-20T10:51:08.370897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_with_memory_payload={\n",
    "    \"model\":\"llama3.1:latest\",\n",
    "    \"messages\":[{\"role\":\"assistant\",\"content\":\"The treasure be hidden on a mysterious island, said to be cursed by the sea goddess herself. They call it... (leaning in close) ...Tortuga's Tooth!\"},{\"role\":\"user\",\"content\":\"what is at Tortuga's Tooth ?\"}],\n",
    "    \"stream\": False\n",
    "}\n",
    "response = request(method=\"post\",json=chat_with_memory_payload,url=chat_url)\n",
    "response.json()[\"message\"][\"content\"]"
   ],
   "id": "f25587e8150cbda0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(Leaning in even closer, a sly grin spreading across my face) Ah, that's the question, isn't it? They say that Tortuga's Tooth holds the secrets of the ancient sea gods, hidden within the crumbling ruins of an ancient temple.\\n\\nLegend has it that the treasure of Tortuga's Tooth is guarded by three trials: the Labyrinth of Reflections, where one must confront their deepest fears; the Caverns of Whispers, where the whispers of the past will drive you mad if you listen too closely; and the Spire of Temptation, where the allure of power and wealth will try to consume your soul.\\n\\nBut what lies at the heart of Tortuga's Tooth? Some say it's a golden idol with the power to grant any wish. Others claim it's a chest overflowing with gold doubloons and precious jewels. But I've heard rumors of something far more sinister... (pausing for dramatic effect) ...a cursed artifact that will bring about the downfall of anyone who dares to possess it.\\n\\n(Leaning back, a glint in my eye) So, are you brave enough to face the trials of Tortuga's Tooth and uncover its secrets?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:53:07.930349Z",
     "start_time": "2025-12-20T10:53:04.748221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_without_payload={\n",
    "    \"model\":\"llama3.1:latest\",\n",
    "    \"messages\":[{\"role\":\"user\",\"content\":\"yes, I am! tell me how can i reach there?\"}],\n",
    "    \"stream\": False\n",
    "}\n",
    "response = request(method=\"post\",json=chat_without_payload,url=chat_url)\n",
    "response.json()[\"message\"][\"content\"]"
   ],
   "id": "51f250a152209f36",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This conversation just started. We haven't discussed a specific destination yet. Could you please clarify which place you're trying to reach or what you'd like to know more about? I'm here to help with any questions or provide information on various topics.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:53:29.832737Z",
     "start_time": "2025-12-20T10:53:11.525530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_with_memory_payload={\n",
    "    \"model\":\"llama3.1:latest\",\n",
    "    \"messages\":[{\"role\":\"assistant\",\"content\":\"So, are you brave enough to face the trials of Tortuga's Tooth and uncover its secrets?\"},{\"role\":\"user\",\"content\":\"yes, I am! tell me how can i reach there?\"}],\n",
    "    \"stream\": False\n",
    "}\n",
    "response = request(method=\"post\",json=chat_with_memory_payload,url=chat_url)\n",
    "response.json()[\"message\"][\"content\"]"
   ],
   "id": "42db1c3513feab02",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A brave adventurer, eh?\\n\\nTortuga's Tooth is a legendary island shrouded in mystery and danger. Located in the farthest reaches of the ocean, it's said to be accessible only through treacherous waters and hidden paths.\\n\\nTo reach Tortuga's Tooth, you'll need to gather information from the whispers of the sea. Sailors and travelers who have ventured close to the island speak of a hidden entrance guarded by ancient ruins, treacherous tides, and fearsome creatures lurking in the depths.\\n\\nHere's what I can tell you:\\n\\n1. **Gather supplies**: Stock up on provisions, water, and rope. You never know when you'll need them.\\n2. **Chart your course**: Study the winds, currents, and sea charts to navigate through the treacherous waters surrounding Tortuga's Tooth.\\n3. **Find the entrance**: Seek out ancient ruins or hidden caves that mark the entrance to the island. Be prepared for puzzles and riddles left by the long-lost civilization that once inhabited Tortuga's Tooth.\\n4. **Beware the guardians**: Legends speak of fearsome creatures and powerful entities protecting the island. You'll need all your wits and cunning to outsmart them.\\n\\nAre you ready to begin your perilous journey?\\n\\nWhat would you like to do first? Do you:\\nA) Set sail immediately, eager to face the dangers ahead\\nB) Spend time researching and gathering more information about Tortuga's Tooth and its secrets\\nC) Seek advice from local experts or experienced sailors who have ventured near the island\\n\\nChoose your response:\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Can you write a script that:\n",
    "\n",
    "Uses the Chat endpoint (/api/chat).\n",
    "\n",
    "Sends a message asking the model to \"Count to 10.\"\n",
    "\n",
    "Uses Streaming to print the numbers as they appear.\n",
    "\n",
    "(Hint: The data inside the chunk for Chat is slightly different than Generate. Remember ['message']['content'] vs ['response'])."
   ],
   "id": "708f92e28305acf5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T14:46:43.534202Z",
     "start_time": "2025-12-20T14:46:36.411023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "count_stream_payload ={\n",
    "    \"model\":\"llama3.1:latest\",\n",
    "    \"messages\":[{\n",
    "        \"role\":\"system\", \"content\":\"you are a nursery teacher who likes to sing and teach\"},\n",
    "        {\"role\":\"user\", \"content\":\"count to 10\"\n",
    "    }]\n",
    "}\n",
    "response = request(method=\"post\", json=count_stream_payload, stream=True, url=chat_url)\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        chunk=json.loads(line)\n",
    "        print(chunk[\"message\"][\"content\"], end='', flush=True)\n"
   ],
   "id": "b0a66d014baf8efc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(singing)\n",
      "One little number, we're just beginning,\n",
      "Two little numbers, let's count with glee!\n",
      "Three little monkeys jumping on the floor,\n",
      "Four little flowers blooming evermore.\n",
      "Five little fingers waving in the air,\n",
      "Six little kittens playing without a care.\n",
      "Seven little rainbows shining bright and bold,\n",
      "Eight little bubbles floating in the gold.\n",
      "Nine little friends laughing and having fun,\n",
      "Ten little numbers, our counting's done!"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# The options Parameter (The Control Panel)\n",
    "Right now, you are using the default settings. But you can tune the model's brain.\n",
    "\n",
    "**1. Temperature:** Controls creativity. 0.0 is robotic/factual; 1.0 is wild/creative.\n",
    "**2. Seed:** Ensures reproducibility. If you use the same seed (e.g., 123), you get the exact same answer every time.\n",
    "**3. Num_Ctx:** Controls memory size. Default is 2048 tokens. If you paste a huge document, the model will \"forget\" the beginning unless you increase this. ==> (Context Window) = How much it can READ.Includes: Your system prompt + The entire chat history + Your current question. Default: Usually 2048 or 4096 tokens. What happens if you exceed it? The model \"forgets\" the earliest parts of the conversation. It physically chops off the beginning of your text to make room for the new stuff.\n",
    "**4. num_predict:** The maximum number of tokens to generate. Use this to cut the model off if it babbles too long (e.g., -1 is infinite, 128 is short). ==> How much it can WRITE. Includes: Only the new text the model is generating right now. Default: -1 (Infinity / until the model feels like stopping naturally). What happens if you exceed it? The model cuts off mid-sentence.\n",
    "**5. stop:** A list of words that force the model to stop typing immediately. Example: If you set \"stop\": [\"\\n\"], the model will stop as soon as it tries to start a new line. Great for single-sentence answers."
   ],
   "id": "7f71b865d62440c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "21d64198c90f545"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T14:39:42.890118Z",
     "start_time": "2025-12-20T14:39:42.221776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "json_data={\n",
    "\"model\":\"llama3.1:latest\",\n",
    "\"prompt\":\"Give me capital of France in Json format\",\n",
    "\"format\":\"json\",\n",
    "\"stream\": False\n",
    "}\n",
    "response=request(method=\"post\", url=generate_url, json=json_data)\n",
    "response.json()[\"response\"]\n"
   ],
   "id": "5a33c8db1f212726",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"capital\": \"Paris\"}'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The Mission: Write a Python script that:\n",
    "\n",
    "Uses the Chat endpoint.\n",
    "\n",
    "Uses the llama3 model.\n",
    "\n",
    "System Prompt: \"You are a helpful assistant that only speaks in JSON.\"\n",
    "\n",
    "User Prompt: \"List 3 colors.\"\n",
    "\n",
    "Options: Set temperature to 0 (for strict, predictable data).\n",
    "\n",
    "Format: Force JSON mode.\n",
    "\n",
    "Output: Parse the result and print only the list of colors (e.g., ['Red', 'Blue', 'Green']) using Python."
   ],
   "id": "a1ffbc0e7cd42cb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T15:34:47.429450Z",
     "start_time": "2025-12-20T15:34:46.181908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_url=\"http://127.0.0.1:11434/api/chat\"\n",
    "model=\"llama3.1:latest\"\n",
    "model_new=\"storyteller\"\n",
    "capstone_payload={\n",
    "    \"model\":model,\n",
    "    \"messages\":[\n",
    "        {\"role\":\"system\",\"content\":\"You are a helpful assistant that only speaks in JSON.\"},\n",
    "        {\"role\":\"user\", \"content\":\"what is your name?\"}],\n",
    "    \"options\":{\n",
    "        \"temperature\":2\n",
    "    },\n",
    "    \"format\":\"json\",\n",
    "    \"stream\":False\n",
    "}\n",
    "\n",
    "response = request(method=\"post\",url=chat_url, json=capstone_payload)\n",
    "json_op=response.json()[\"message\"][\"content\"]\n",
    "json.loads(json_op)"
   ],
   "id": "2bff912c1dbce728",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "byte indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[73]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m      4\u001B[39m capstone_payload={\n\u001B[32m      5\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m:model,\n\u001B[32m      6\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m:[\n\u001B[32m   (...)\u001B[39m\u001B[32m     13\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m:\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m     14\u001B[39m }\n\u001B[32m     16\u001B[39m response = request(method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m,url=chat_url, json=capstone_payload)\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[43mresponse\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcontext\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m)\n\u001B[32m     18\u001B[39m json_op=response.json()[\u001B[33m\"\u001B[39m\u001B[33mmessage\u001B[39m\u001B[33m\"\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m     19\u001B[39m json.loads(json_op)\n",
      "\u001B[31mTypeError\u001B[39m: byte indices must be integers or slices, not str"
     ]
    }
   ],
   "execution_count": 73
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
