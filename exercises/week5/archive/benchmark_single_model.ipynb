{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T22:06:40.623101Z",
     "start_time": "2025-12-22T22:06:40.568394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Transaction(BaseModel):\n",
    "    txn_id:str = Field(...)\n",
    "    txn_fraud_category:str=Field(...)\n",
    "    reasoning:str = Field(...)\n",
    "\n",
    "class TransactionAnalysis(BaseModel):\n",
    "    transactions : List[Transaction]\n"
   ],
   "id": "9fcdc9cf08677662",
   "outputs": [],
   "execution_count": 261
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T22:06:40.651536Z",
     "start_time": "2025-12-22T22:06:40.623961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_accuracy_score(model_result)->float:\n",
    "    print(\"model_result: \\n\",model_result)\n",
    "    results_file_name = \"../transactions_feed_results.json\"\n",
    "    if os.path.exists(results_file_name):\n",
    "        with open(results_file_name, 'r') as rf:\n",
    "            actual_result=json.load(rf)\n",
    "    print(\"actual_result: \\n\",actual_result)\n",
    "    # 1. Prepare the Data\n",
    "    # Assume 'model_output' is the dictionary you received from the LLM\n",
    "    model_predictions = model_result['transactions']\n",
    "\n",
    "    # Assume 'ground_truth_list' is your actual_result list\n",
    "    ground_truth_list = actual_result\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. Create the Lookup Dictionary (The Magic Step ✨)\n",
    "    # We turn the list into a dict keyed by 'txn_id'\n",
    "    # ---------------------------------------------------------\n",
    "    truth_lookup = {item['txn_id']: item for item in ground_truth_list}\n",
    "\n",
    "    # Now truth_lookup looks like:\n",
    "    # {\n",
    "    #    'TXN_101': {'txn_id': 'TXN_101', 'txn_fraud_category': 'legitimate', ...},\n",
    "    #    'TXN_102': {'txn_id': 'TXN_102', 'txn_fraud_category': 'legitimate', ...}\n",
    "    # }\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. Iterate and Compare\n",
    "    # ---------------------------------------------------------\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for prediction in model_predictions:\n",
    "        txn_id = prediction['txn_id']\n",
    "\n",
    "        # Get the model's guess\n",
    "        predicted_label = prediction['txn_fraud_category']\n",
    "\n",
    "        # Retrieve the TRUTH instantly using the ID\n",
    "        if txn_id in truth_lookup:\n",
    "            actual_label = truth_lookup[txn_id]['txn_fraud_category']\n",
    "\n",
    "            # --- CRITICAL: Case-Insensitive Comparison ---\n",
    "            # Your model returned \"Legitimate\" (Title Case)\n",
    "            # Your data has \"legitimate\" (Lower Case)\n",
    "            if predicted_label.lower() == actual_label.lower():\n",
    "                correct_count += 1\n",
    "                print(f\"✅ {txn_id}: Match!\")\n",
    "            else:\n",
    "                print(f\"❌ {txn_id}: Mismatch (Model: {predicted_label}, Actual: {actual_label})\")\n",
    "\n",
    "            total_count += 1\n",
    "        else:\n",
    "            print(f\"⚠️ Warning: Model predicted {txn_id}, but it's not in our ground truth!\")\n",
    "\n",
    "    # 4. Final Score\n",
    "    accuracy = (correct_count / total_count) * 100\n",
    "    print(f\"\\nFinal Accuracy: {accuracy}%\")\n",
    "    return round(accuracy,2)"
   ],
   "id": "12208fb459a777f7",
   "outputs": [],
   "execution_count": 262
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T22:06:40.707071Z",
     "start_time": "2025-12-22T22:06:40.681997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "txn_file_name= \"../transactions_feed.json\"\n",
    "if os.path.exists(txn_file_name):\n",
    "    with open(txn_file_name, 'r') as f:\n",
    "        txns = json.load(f)\n",
    "    serialized_txn = json.dumps(txns, indent=2)\n",
    "    # print(serialized_txn)\n",
    "\n"
   ],
   "id": "dc8f0dfcd84d94f1",
   "outputs": [],
   "execution_count": 263
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T22:06:40.792122Z",
     "start_time": "2025-12-22T22:06:40.714818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ollama\n",
    "# --- 1. Setup Models ---\n",
    "models_to_evaluate = [\n",
    "                        'llama3.2:latest',\n",
    "                       # 'mistral:7b',\n",
    "                       #  'phi3:mini'\n",
    "]\n",
    "print(\"Checking available models...\")\n",
    "available_models = [mod['model'] for mod in ollama.list()['models']]\n",
    "available_models"
   ],
   "id": "dffca3031cf836a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking available models...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['llama3.2:latest',\n",
       " 'storyteller:latest',\n",
       " 'mistral:7b',\n",
       " 'llama3.1:latest',\n",
       " 'phi3:mini',\n",
       " 'llama3.2:3b']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 264
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T22:06:40.823403Z",
     "start_time": "2025-12-22T22:06:40.794024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"You are a Financial Fraud Investigator. Analyse the transactions submitted and categorize as Legitimate or Suspicious. As output, for each transaction, give Category (as txn_fraud_category) and Reasoning (as reasoning) in JSON\"\n",
    "payload=[\n",
    "    {\"role\" :\"system\",\n",
    "     \"content\":system_prompt},\n",
    "    {\"role\":\"user\",\n",
    "     \"content\":serialized_txn}\n",
    "]\n",
    "\n",
    "# options_map = {\n",
    "#     \"deterministic\": {\"temperature\": 0.1, \"top_p\": 0.95},\n",
    "#     # \"balanced\": {\"temperature\": 0.5, \"top_p\": 0.9},\n",
    "#     # \"creative\": {\"temperature\": 0.9, \"top_p\": 0.85}\n",
    "\n",
    "options= {\n",
    "   \"temperature\": 0.1, \"top_p\": 0.95}"
   ],
   "id": "42586835f3a293ce",
   "outputs": [],
   "execution_count": 265
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T22:07:00.226152Z",
     "start_time": "2025-12-22T22:06:40.824567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluation_results = []\n",
    "\n",
    "for model in models_to_evaluate:\n",
    "    if model not in available_models:\n",
    "        # print(f\"\\nModel '{model}' is missing. Pulling now...\")\n",
    "        response = ollama.pull(model, stream=True)\n",
    "        for progress in response:\n",
    "            print(f\"  {progress.get('status')}\", end='\\r')\n",
    "        # print(f\"\\nFinished pulling {model}\")\n",
    "    else:\n",
    "        print(f\"Model '{model}' is already available, processing the request now.....\")\n",
    "        model_eval={}\n",
    "        model_eval[\"model\"]=model\n",
    "        result = ollama.chat(model=model, messages=payload, stream=False, options=options, format=\"json\")\n",
    "        assistant_msg = result['message']['content']\n",
    "        # print(f\"result type :\\n {type(assistant_msg)}\")\n",
    "        # print(f\"result :\\n {assistant_msg}\")\n",
    "        accuracy_score=calculate_accuracy_score(json.loads(assistant_msg))\n",
    "        # Convert to seconds first\n",
    "        duration_ns = result['total_duration']\n",
    "        total_seconds = duration_ns / 1_000_000_000\n",
    "        # Calculate minutes and remaining seconds\n",
    "        minutes, seconds = divmod(total_seconds, 60)\n",
    "        speed_display = f\"{int(minutes)}m {seconds:.2f}s\"\n",
    "        print(f\"Time taken: {speed_display}\")\n",
    "        print(f\"Accuracy: {accuracy_score}\")\n",
    "        model_eval[\"duration\"]=speed_display\n",
    "        model_eval[\"accuracy\"]=accuracy_score\n",
    "        evaluation_results.append(model_eval)\n"
   ],
   "id": "a78b921623a4ed63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'llama3.2:latest' is already available, processing the request now.....\n",
      "model_result: \n",
      " {'transactions': [{'txn_id': 'TXN_101', 'txn_fraud_category': 'Legitimate', 'reasoning': 'The merchant and location are consistent with a legitimate transaction.'}, {'txn_id': 'TXN_102', 'txn_fraud_category': 'Suspicious', 'reasoning': 'The location is inconsistent with the merchant, suggesting potential identity theft or fake address.'}]}\n",
      "actual_result: \n",
      " [{'txn_id': 'TXN_101', 'txn_details': {'card_number': '1234-5678-9012-3456', 'timestamp': '2023-10-27T09:00:00Z', 'amount': 4.5, 'merchant': 'Daily Grind Coffee', 'category': 'Food & Drink', 'location': 'London, UK'}, 'txn_fraud_category': 'legitimate'}, {'txn_id': 'TXN_102', 'txn_details': {'card_number': '1234-5678-9012-3456', 'timestamp': '2023-10-27T09:00:00Z', 'amount': 4.5, 'merchant': 'Daily Grind Coffee', 'category': 'Food & Drink', 'location': 'India, UK'}, 'txn_fraud_category': 'legitimate'}]\n",
      "✅ TXN_101: Match!\n",
      "❌ TXN_102: Mismatch (Model: Suspicious, Actual: legitimate)\n",
      "\n",
      "Final Accuracy: 50.0%\n",
      "Time taken: 0m 19.35s\n",
      "Accuracy: 50.0\n"
     ]
    }
   ],
   "execution_count": 266
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T22:07:00.491859Z",
     "start_time": "2025-12-22T22:07:00.274986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(evaluation_results)\n",
    "\n",
    "df.round(2)"
   ],
   "id": "efff80786ed21fdb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             model   duration  accuracy\n",
       "0  llama3.2:latest  0m 19.35s      50.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>duration</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama3.2:latest</td>\n",
       "      <td>0m 19.35s</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 267
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
